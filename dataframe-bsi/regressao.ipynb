{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Load the dataset\n",
    "df_dados = pd.read_csv('df_bsi_TR.csv', sep=',')\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df_dados.drop(columns=['tempo_relativo']).to_numpy()\n",
    "y = df_dados['tempo_relativo'].to_numpy()\n",
    "\n",
    "# Define SVR models with different kernels\n",
    "svr_rbf = SVR(kernel=\"rbf\", C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = SVR(kernel=\"linear\", C=100, gamma=\"auto\")\n",
    "svr_poly = SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)\n",
    "\n",
    "# Fit the models\n",
    "svrs = [svr_rbf, svr_lin, svr_poly]\n",
    "kernel_label = [\"RBF\", \"Linear\", \"Polynomial\"]\n",
    "model_color = [\"m\", \"c\", \"g\"]\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 10), sharey=True)\n",
    "for ix, svr in enumerate(svrs):\n",
    "    svr.fit(X, y)\n",
    "    y_pred = svr.predict(X)\n",
    "    \n",
    "    axes[ix].scatter(X[:, 0], y, color='k', s=20, label=\"Data\")\n",
    "    axes[ix].scatter(X[:, 0], y_pred, color=model_color[ix], s=50, label=\"{} model\".format(kernel_label[ix]), alpha=0.6)\n",
    "    \n",
    "    axes[ix].legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=1, fancybox=True, shadow=True)\n",
    "    axes[ix].set_title(\"{} SVR\".format(kernel_label[ix]))\n",
    "\n",
    "fig.text(0.5, 0.04, \"Feature 1\", ha=\"center\", va=\"center\")\n",
    "fig.text(0.06, 0.5, \"tempo_relativo\", ha=\"center\", va=\"center\", rotation=\"vertical\")\n",
    "fig.suptitle(\"Support Vector Regression\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carregar os dados\n",
    " # Substitua pelo seu caminho de arquivo\n",
    "data = pd.read_csv('tabela_final.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['semestre_dividido', 'ch_cumprida_dividida'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 3. Seleção de Variáveis (exemplo simplificado)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[39m=\u001b[39m data[[\u001b[39m'\u001b[39;49m\u001b[39msemestre_dividido\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mch_cumprida_dividida\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[1;32m      3\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# 1 se evadiu, 0 se não evadiu\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# 4. Modelagem\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[39mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[39mif\u001b[39;00m nmissing \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['semestre_dividido', 'ch_cumprida_dividida'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# 3. Seleção de Variáveis (exemplo simplificado)\n",
    "X = data[['semestre_dividido', 'ch_cumprida_dividida']]\n",
    "y = data['status']  # 1 se evadiu, 0 se não evadiu\n",
    "\n",
    "# 4. Modelagem\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Treinamento e Validação\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliação do Modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia: {accuracy}')\n",
    "print(f'Precisão: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39m# Treinar o modelo de regressão logística\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[0;32m---> 25\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Fazer previsões no conjunto de teste\u001b[39;00m\n\u001b[1;32m     28\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1246\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1244\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m   1245\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 1246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1250\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1254\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. Carregar os dados\n",
    " # Substitua pelo seu caminho de arquivo\n",
    "df = pd.read_csv('tabela_final.csv', sep=';')\n",
    "\n",
    "# Definir o target\n",
    "df['evasao'] = df['status'].apply(lambda x: 1 if x == -1 else 0)\n",
    "\n",
    "# Selecionar as features (colunas de reprovação)\n",
    "features = [col for col in df.columns if col.endswith('_REPROVADO')]\n",
    "\n",
    "# Criar X e y\n",
    "X = df[features]\n",
    "y = df['evasao']\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo de regressão logística\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar a performance do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Obter os coeficientes do modelo\n",
    "coef_df = pd.DataFrame({'Disciplina': features, 'Coeficiente': model.coef_[0]})\n",
    "coef_df = coef_df.sort_values(by='Coeficiente', ascending=False)\n",
    "\n",
    "print(coef_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Precision: 0.94\n",
      "Recall: 0.99\n",
      "F1 Score: 0.97\n",
      "Confusion Matrix:\n",
      "[[ 36  10]\n",
      " [  1 158]]\n",
      "                                            Coeficiente\n",
      "FUNDAMENTOS DE SISTEMAS DE INFORMAÇÃO          1.082961\n",
      "ESTRUTURA DE DADOS_REPROVADO                   0.912692\n",
      "PROGRAMAÇÃO ORIENTADA A OBJETOS I_APROVADO     0.711454\n",
      "MATEMÁTICA FINANCEIRA                          0.665336\n",
      "EMPREENDEDORISMO EM INFORMÁTICA_APROVADO       0.659360\n",
      "...                                                 ...\n",
      "ENGENHARIA DE SOFTWARE I                      -0.923658\n",
      "ENGENHARIA DE SOFTWARE I_APROVADO             -1.005640\n",
      "PROGRAMAÇÃO_APROVADO                          -1.138788\n",
      "ano_ingresso                                  -2.185628\n",
      "ultimo_periodo                                -2.233724\n",
      "\n",
      "[97 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 1. Carregar os dados\n",
    " # Substitua pelo seu caminho de arquivo\n",
    "df = pd.read_csv('tabela_final.csv', sep=';')\n",
    "\n",
    "# 2. Pré-processamento dos dados\n",
    "# Convertendo colunas categóricas para numéricas\n",
    "df['sexo'] = df['sexo'].replace({'M': 1, 'F': 0})\n",
    "\n",
    "# Criar a coluna 'evadido' baseada no último período disponível\n",
    "ultimo_periodo_disponivel = df['ultimo_periodo'].max()\n",
    "df['status'] = df['ultimo_periodo'] < ultimo_periodo_disponivel\n",
    "\n",
    "# Remover colunas não relevantes\n",
    "df = df.drop(columns=['discente'])  # Remover a coluna 'discente' ou outras que não são úteis para a previsão\n",
    "\n",
    "# 3. Separar as variáveis independentes (X) e a variável dependente (y)\n",
    "X = df.drop(columns=['status'])\n",
    "y = df['status']\n",
    "\n",
    "# 4. Imputação de valores ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# 5. Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 6. Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 7. Treinamento do modelo\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 9. Avaliar o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# 10. Coeficientes do modelo\n",
    "coeficientes = pd.DataFrame(model.coef_[0], index=df.drop(columns=['status']).columns, columns=['Coeficiente']).sort_values(by='Coeficiente', ascending=False)\n",
    "print(coeficientes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m reg \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 6\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(x, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      8\u001b[0m reg\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     10\u001b[0m y_pred \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(x_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "reg = LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "y_pred = reg.predict(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "print('Coeficiente: \\n', reg.coef_)\n",
    "\n",
    "print('MSE: %f' % np.mean((reg.predict(x_test) - y_test) ** 2))\n",
    "\n",
    "print('Variance score: %.2f' % reg.score(x_test, y_test))\n",
    "\n",
    "#print('RMSE:', % np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "#print('MAE: %', np.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "plt.plot(np.linspace(-1, 1, len(y_test)), y_test, label='Notas - Real', color='b')\n",
    "plt.plot(np.linspace(-1, 1, len(y_pred)), y_pred, label='Notas - Predita', color='g')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
