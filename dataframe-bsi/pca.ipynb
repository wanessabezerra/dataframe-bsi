{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, confusion_matrix\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Carregar os dados\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#df_dados = pd.read_csv('df_bsi_sem_ativo.csv', sep=',')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Filtrar as classes com mais de uma instância\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_dados\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m     21\u001b[0m classes_to_keep \u001b[38;5;241m=\u001b[39m class_counts[class_counts \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m     22\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df_dados[df_dados[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(classes_to_keep)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_dados' is not defined"
     ]
    }
   ],
   "source": [
    "# Importando as Bibliotecas Necessárias\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregando e Preparando os Dados\n",
    "df = pd.read_csv('df_total.csv', sep=',')\n",
    "\n",
    "\n",
    "# Remova a variável dependente se estiver presente\n",
    "if 'status' in df.columns:\n",
    "    df = df.drop(columns=['status'])\n",
    "\n",
    "# Padronizando os dados (muito importante para PCA)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Aplicando PCA\n",
    "# Inicializando o PCA\n",
    "pca = PCA(n_components=None)  # n_components=None significa que manteremos todos os componentes\n",
    "df_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Criando um DataFrame com os componentes principais\n",
    "pca_columns = [f'PC{i+1}' for i in range(df.shape[1])]\n",
    "df_pca = pd.DataFrame(df_pca, columns=pca_columns)\n",
    "\n",
    "# Explicando a Variância\n",
    "# Variância explicada por cada componente principal\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Plotando a variância explicate\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.5, align='center', label='individual explained variance')\n",
    "plt.step(range(1, len(explained_variance) + 1), explained_variance.cumsum(), where='mid', label='cumulative explained variance')\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.show()\n",
    "\n",
    "# Analisando a Importância das Variáveis\n",
    "# Coeficientes dos componentes principais\n",
    "loadings = pca.components_.T\n",
    "\n",
    "# Criando um DataFrame para facilitar a visualização\n",
    "loadings_df = pd.DataFrame(loadings, columns=pca_columns, index=df.columns)\n",
    "\n",
    "# Visualizando as primeiras componentes principais\n",
    "print(\"Coeficientes (Loadings) das variáveis para cada componente principal:\")\n",
    "print(loadings_df)\n",
    "\n",
    "# Para uma visualização mais completa, você pode salvar ou plotar o DataFrame dos loadings\n",
    "# Plotando os coeficientes das variáveis para as duas primeiras componentes principais\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(loadings_df.index, loadings_df['PC1'], alpha=0.7, label='PC1')\n",
    "plt.bar(loadings_df.index, loadings_df['PC2'], alpha=0.7, label='PC2')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Loading Scores')\n",
    "plt.title('Feature Importance for PC1 and PC2')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
